<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Samuel Toriel's Blog</title>
 <link href="http://0.0.0.0:4000/atom.xml" rel="self"/>
 <link href="http://0.0.0.0:4000/"/>
 <updated>2023-10-23T17:06:32-05:00</updated>
 <id>http://0.0.0.0:4000</id>
 <author>
   <name></name>
   <email></email>
 </author>

 
 <entry>
   <title>Project Nudge: A Beech Valley Software Project</title>
   <link href="http://0.0.0.0:4000/productdevelopment/staffing/recruiting/leading/2021/10/29/project-nudge-a-beech-valley-software-project.html"/>
   <updated>2021-10-29T00:00:00-05:00</updated>
   <id>http://0.0.0.0:4000/productdevelopment/staffing/recruiting/leading/2021/10/29/project-nudge-a-beech-valley-software-project</id>
   <content type="html">&lt;h1 id=&quot;idea-to-production-a-beech-valley-project&quot;&gt;Idea to Production: A Beech Valley Project&lt;/h1&gt;

&lt;p&gt;Beech Valley can be thought of as the gig economy for the accounting industry. We operate as a fairly lean team so how we approach executing work comes with that in mind.&lt;/p&gt;

&lt;p&gt;Here‚Äôs how we ideated, planned, and executed one of our latest successful projects here at Beech Valley.&lt;/p&gt;

&lt;p&gt;An important aspect of the work described here requires background on how our product works. Beech Valley has projects with clients and within each project is a hiring pipeline. Within each pipeline are a number of stages a candidate has to go through to get to the end goal: Hired or Disqualified. Something we noticed is that candidates often sit longer than expected in a certain stage of the pipeline. The goal of the project is to move people along the pipeline quicker so they are never stuck for too long (and that they reach an end state!).&lt;/p&gt;

&lt;h2 id=&quot;ideation&quot;&gt;üí°Ideation&lt;/h2&gt;

&lt;p&gt;The first step in our project lifecycle was determining the root issue. Why were people getting stuck in specific states? To identify the problem, we interviewed a handful of people on our internal team to help give us some clues.&lt;/p&gt;

&lt;p&gt;We did three different 30-minute sessions where we had a product designer, an engineering lead (me) and an internal employee of our app sit down together for a chat. Our goal was to learn from the internal employee‚Äôs workflow. The conversation would usually start with the engineer or product designer setting the initial context by asking something along the lines of ‚ÄúWalk us through a typical pipeline‚Äù and then asking questions along the way to tease out what‚Äôs happening, why it‚Äôs happening, and which steps we can take to fix the issue.&lt;/p&gt;

&lt;p&gt;After the 30-minute session, the product development team would debrief and share some notes together until all sessions were completed. This gave us a much better idea of what was going on and at this point we could have a longer session on what we want to do to solve it.&lt;/p&gt;

&lt;p&gt;In this case our engineering lead (me) took the reigns for this project and started a product design document outlining the scenarios we wanted to solve given the information we had learned. We scheduled some time as a team to talk through the design document and brainstormed how to solve the different scenarios. What was initially a smattering of individual solutions started taking shape into something more.&lt;/p&gt;

&lt;h2 id=&quot;planning&quot;&gt;üìÑPlanning&lt;/h2&gt;

&lt;p&gt;At this stage, we now had clear goals for our project. We wanted to reduce time spent in each pipeline state. What we found out through ideation is that each pipeline state has an input and an output. The input and output can be owned by different people and requires action on their part in order to hand it off to the next person. Specifically, the people involved in our pipeline include the client (person who wants to hire someone), the consultant (person who wants to be hired), and an internal Beech Valley representative.&lt;/p&gt;

&lt;p&gt;The primary pain point we uncovered from the interviews is that people simply needed a reminder that it was their turn to take action in a certain stage of the pipeline.&lt;/p&gt;

&lt;p&gt;Knowing this, we created three phases to our project in the order of value we thought it would bring to the business. In addition if we got interrupted in our workflow we could shelve a phase until we could get back to it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phase One&lt;/strong&gt;: We enable our internal team to know exactly when a stage was overdue so they could take action in the form of a reminder. No more rustling through notes, emails, or self created reminders.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phase Two&lt;/strong&gt;: We remind consultants when we have potential projects available for them through automated interest checks and reminders.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Phase Three&lt;/strong&gt;: We give our clients a daily rundown of where their projects are at and if they need attention through an automated email digest.&lt;/p&gt;

&lt;h2 id=&quot;execution&quot;&gt;üíªExecution&lt;/h2&gt;

&lt;p&gt;We immediately planned out and started Phase One. We had our product designer come up with some ideas about what the features we wanted could look like and agreed on a plan of action. The engineering lead (me) took the first pass at writing out a few tickets and then we held a planning discussion with the rest of the engineering team to make sure it was the approach we wanted to take.&lt;/p&gt;

&lt;p&gt;An interesting point in our execution phase is that we didn‚Äôt write out any tickets or designs for Phase Two or Three initially. We just had a general idea of how we wanted to approach them from our product design document. What this allowed our team to do was interweave some other projects in before we started Phase Two and Three.&lt;/p&gt;

&lt;p&gt;In terms of tech used during execution, most of the code consisted of a bit of React magic, sprinkles of GraphQL API schema changes, a smattering of new Postgres queries using Objection.js, and a handful of background pg-boss jobs to calculate or send emails outside the request-response lifecycle. All of which were wrapped with a set of tests in jest to make sure it all worked. A neat thing about this project is that most of it is written in one monorepo where the frontend, api, and background jobs all live together using nx to manage both projects and shared libraries.&lt;/p&gt;

&lt;h2 id=&quot;closing&quot;&gt;Closing&lt;/h2&gt;

&lt;p&gt;One improvement we could have made in execution is in the first phase, we should have picked a few metrics to help us identify that we were accomplishing our goal and measuring it. This is something we did when we started on phase two and three and immediately put those up front to help us know if our changes were successful.&lt;/p&gt;

&lt;p&gt;Here are the key results from our project.&lt;/p&gt;

&lt;p&gt;üéâ Phase 1 took 31 stories and a lot of kudos from our internal team for making their lives easier.
&lt;br /&gt;
üéâ Phase 2 took 12 stories and increased our response rates from consultants by 15%
&lt;br /&gt;
üéâ Phase 3 took 9 stories and while still in progress of rolling out the feature we noticed an uptick in responses within thirty minutes after hitting a clients inbox.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Spinnaker deployment pipelines</title>
   <link href="http://0.0.0.0:4000/devops/infrastructure/deploymenttools/2016/02/08/spinnaker-deployment-pipelines.html"/>
   <updated>2016-02-08T00:00:00-06:00</updated>
   <id>http://0.0.0.0:4000/devops/infrastructure/deploymenttools/2016/02/08/spinnaker-deployment-pipelines</id>
   <content type="html">
&lt;p&gt;I‚Äôd like to especially thank &lt;a href=&quot;https://twitter.com/tomaslin&quot;&gt;Tom√°s Lin&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/cfieber&quot;&gt;Cameron Fieber&lt;/a&gt; for which the below would not be possible without their endless involvement in the &lt;a href=&quot;https://spinnakerteam.slack.com&quot;&gt;#spinnakerteam&lt;/a&gt; slack channel.&lt;/p&gt;

&lt;p&gt;One of the questions I see come up quite often in slack are how to model deployment pipelines which do not follow&lt;/p&gt;

&lt;p&gt;&lt;code&gt;trigger&lt;/code&gt; &lt;span style=&quot;font-weight:bold; font-size: 26px;&quot;&gt;‚á®&lt;/span&gt; &lt;code&gt;bake image with *nix package artifact&lt;/code&gt; &lt;span style=&quot;font-weight:bold; font-size: 26px;&quot;&gt;‚á®&lt;/span&gt; &lt;code&gt;deploy image&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Different organizations have their own restrictions or legacy systems which require alternative deployment methods to the above. Because Jenkins jobs are a first class citizen in Spinnaker this gives it the ability to execute complex tasks and pass on any information required from a previous step. I will outline out how to take advantage of this.&lt;/p&gt;

&lt;p&gt;One very important concept in pipelines is understanding where and how the Spring Expression Language (SpEL) can be used. A few of these rules are outlined below:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spinnaker uses uses the delimiter &lt;code&gt;${}&lt;/code&gt; for SpEL.&lt;/li&gt;
  &lt;li&gt;Variables can be defined in several ways:
    &lt;ol&gt;
      &lt;li&gt;The first stage of a pipeline allows defining parameters which can be accessed via &lt;code&gt;${ parameters.key }&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;The first stage of a pipeline allows parameters to be read from a trigger and accessed via &lt;code&gt;${ trigger.properties.key }&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Read from a Jenkins job artifact that is yaml, json, or Java properties file and accessed via &lt;code&gt;${ key }&lt;/code&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Deploy Stage&lt;/code&gt; will create an array called &lt;code&gt;${ deployedServerGroups }&lt;/code&gt; which gives enough information to access the deployed cluster.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As of this writing (2016-02-08) the &lt;code&gt;Deploy Stage&lt;/code&gt; in Spinnaker ‚Äúrequires‚Äù a &lt;code&gt;Bake Stage&lt;/code&gt; or &lt;code&gt;Find Image Stage&lt;/code&gt;. When I say ‚Äúrequires‚Äù I mean that it will display a warning message which can be ignored as it does not prevent the pipeline from executing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-pipelines/bake_or_find_error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To get around using the &lt;code&gt;Bake Stage&lt;/code&gt; or &lt;code&gt;Find Image Stage&lt;/code&gt; we‚Äôll have to edit the pipeline json for the &lt;code&gt;Deploy Stage&lt;/code&gt; using the key &lt;code&gt;amiName&lt;/code&gt; to inject the image id we want to use. While a specific image id might be a show stopper we can dynamically pick the image id through the use of use of the aforementioned SpEL rules and variable access.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-pipelines/spinnaker_edit_json.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;requisiteStageRefIds&quot;: [
    &quot;1&quot;
  ],
  &quot;refId&quot;: &quot;2&quot;,
  &quot;type&quot;: &quot;deploy&quot;,
  &quot;name&quot;: &quot;Deploy&quot;,
  &quot;clusters&quot;: [
    {
      &quot;application&quot;: &quot;some application name&quot;,
      &quot;strategy&quot;: &quot;redblack&quot;,
      &quot;provider&quot;: &quot;aws&quot;,
      &quot;cloudProvider&quot;: &quot;aws&quot;,
      ...
      &quot;amiName&quot;: &quot;${image_id}&quot;, &amp;lt;=== Inject your own image id
      ...
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For our own organization we actually have a fairly active rotating AMI id as we make changes to the base AMI used for our applications so it updates often. To keep this rotating AMI id fresh for our 35+ microservices we put this information into a github repo, along with other context for each application to help it deploy properly. Upon bootup we have our applications bootstrap themselves in the simplest way possible.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Download a JAR file from S3&lt;/li&gt;
  &lt;li&gt;Export environment variables for use by the application JAR&lt;/li&gt;
  &lt;li&gt;Tag our system&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To accomplish this for so many microservices we decided to create a github repo which spits out the configuration for bootstrap in the form of User Data (this is catered towards AWS):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;root
 \__applications
   \__service1
     \__production.yaml
     \__staging.yaml
    \__service2
      \__production.yaml
      \__staging.yaml
      \__beta.yaml
 \__scripts
   \__configuration_script.py  
   \__ami_table.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is what &lt;a href=&quot;https://gist.github.com/riltsken/84004a3b6964823e3ae6&quot;&gt;configuration_script.py&lt;/a&gt; looks like. It takes in an application configuration as shown below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;ami_name: java_ami_hvm
environment: staging
tags:
  role: webapplication
  team: ops

userdata: |
  export CONFIG=&apos;staging.yaml&apos;
  export JAVA_OPTS=&apos;-Xmx2500m -server -XX:+UseCompressedOops -XX:+UseParNewGC -Dfile.encoding=UTF-8
  export JAVA_HOME=&apos;/opt/java8&apos;
  export JAVA_RUN_COMMAND=&apos;app.jar&apos;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The resulting transformation after going through our script would be a yaml file like the following to be used as variables in our pipeline.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;application_name: &apos;service1&apos;
environment: &apos;staging&apos;
base64_userdata: &apos;ZXhwb3J0IFJFVklTSU9OPXMzOi8vJHtidWNrZXR9L3NlcnZpY2UxLyR7Y29tbWl0aGFzaH0vJHt0aW1lc3RhbXB9CmV4cG9ydCBUQUdTPSd7InJvbGUiOiAid2ViYXBwbGljYXRpb24iLCAidGVhbSI6ICJvcHMiLCAiZW52aXJvbm1lbnQiOiAic3RhZ2luZyIsICJuYW1lIjogInNlcnZpY2UxIicKZXhwb3J0IEFQUExJQ0FUSU9OX05BTUU9c2VydmljZTEKZXhwb3J0IENPTkZJRz0nc3RhZ2luZy55YW1sJwpleHBvcnQgSkFWQV9PUFRTPSctWG14MjUwMG0gLXNlcnZlciAtWFg6K1VzZUNvbXByZXNzZWRPb3BzIC1YWDorVXNlUGFyTmV3R0MgLURmaWxlLmVuY29kaW5nPVVURi04CmV4cG9ydCBKQVZBX0hPTUU9Jy9vcHQvamF2YTgnCmV4cG9ydCBKQVZBX1JVTl9DT01NQU5EPSdhcHAuamFyJwo=&apos;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the transformed &lt;code&gt;base64_userdata&lt;/code&gt; in plaintext is&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;export REVISION=s3://${bucket}/service1/${commithash}/${timestamp}
export TAGS=&apos;{&quot;role&quot;: &quot;webapplication&quot;, &quot;team&quot;: &quot;ops&quot;, &quot;environment&quot;: &quot;staging&quot;, &quot;name&quot;: &quot;service1&quot;&apos;
export APPLICATION_NAME=service1
export CONFIG=staging.yaml
export JAVA_OPTS=&apos;-Xmx2500m -server -XX:+UseCompressedOops -XX:+UseParNewGC -Dfile.encoding=UTF-8&apos;
export JAVA_HOME=/opt/java8
export JAVA_RUN_COMMAND=app.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now what does this look like on the spinnaker side?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-pipelines/pipeline.png&quot;&gt;Link to big&lt;/a&gt;
&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-pipelines/pipeline.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And in the &lt;code&gt;Deploy Stage&lt;/code&gt; the &lt;code&gt;Advanced Settings&lt;/code&gt; of our &lt;code&gt;Server Group&lt;/code&gt;
&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-pipelines/pipelines2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now our AMI has all the information it needs upon booting up in its autoscaling group to correctly tag itself, download its jar file, add additional motd information, and setup configuration for the application to boot.&lt;/p&gt;

&lt;p&gt;If one wanted to execute something on the server group AFTER it has been deployed we can do that as well. A common thing would be integration tests or ansible for most people before enabling the instances in their LoadBalancer. As I mentioned before the &lt;code&gt;Deploy Stage&lt;/code&gt; adds information about the deploy to the &lt;code&gt;deployedServerGroups&lt;/code&gt; array. If one wanted to attempt to run something against that server group you could access from the following information provided by a deployed server group.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-shell&quot;&gt;{account=staging,capacity={desired=1, max=1, min=1},
parentStage=23452655¬≠c6de¬≠4aac¬≠b529¬≠55e1357dfee7, region=us¬≠east1,
ami=ami¬≠999af013, storeType=ebs, vmType=pv, serverGroup=service1-049}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Specifically, I created a jenkins job which accepted &lt;code&gt;${ deployedServerGroups[0].serverGroup }&lt;/code&gt; and then accessed the cluster by looking up the tag via aws cli.&lt;/p&gt;

&lt;p&gt;Hopefully these are useful tidbits for getting started. Good luck on your pipeline creation!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Setting up Spinnaker authentication with Okta and SAML</title>
   <link href="http://0.0.0.0:4000/devops/infrastructure/deploymenttools/2015/12/08/setup-okta-saml-with-spinnaker.html"/>
   <updated>2015-12-08T00:00:00-06:00</updated>
   <id>http://0.0.0.0:4000/devops/infrastructure/deploymenttools/2015/12/08/setup-okta-saml-with-spinnaker</id>
   <content type="html">
&lt;h2 id=&quot;as-of-release-2540-gate-has-changed-the-way-the-saml-authentication-mechanism-is-configured-please-follow-the-migration-guide-if-you-stumbled-on-this-guide-looking-for-how-to-configure-saml-follow-the-securing-spinnaker-guide-instead&quot;&gt;As of release &lt;em&gt;2.54.0&lt;/em&gt;, Gate has changed the way the SAML authentication mechanism is configured. Please follow the &lt;a href=&quot;http://www.spinnaker.io/docs/gate-saml-config&quot;&gt;migration guide&lt;/a&gt;. If you stumbled on this guide looking for how to configure SAML follow the &lt;a href=&quot;http://www.spinnaker.io/docs/securing-spinnaker#section-saml-2-0&quot;&gt;securing spinnaker guide&lt;/a&gt; instead&lt;/h2&gt;

&lt;p&gt;Recently Netflix in collaboration with Google, Amazon, Microsoft, and CloudFoundry have released a new OSS deployment application called Spinnaker (Asgard 2.0). Our team has been going through and setting up this tool to be production ready for our environments as we had been planning to move to a new deployment tool anyway. This post in particular will go into the details of setting up SAML authentication through Okta with Spinnaker. Although this is specific to Okta the concepts could be adapted to any other SAML Identity Provider.&lt;/p&gt;

&lt;p&gt;At &lt;a href=&quot;https://www.fullcontact.com/&quot;&gt;FullContact&lt;/a&gt; we use &lt;a href=&quot;https://www.okta.com/&quot;&gt;Okta&lt;/a&gt; to handle all of our Authentication which is backed by an LDAP provider called &lt;a href=&quot;https://www.jumpcloud.com/&quot;&gt;JumpCloud&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;setting-up-okta&quot;&gt;Setting up Okta&lt;/h1&gt;

&lt;h2 id=&quot;step-1&quot;&gt;Step 1&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-saml/spinnaker_okta_integration_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;step-2&quot;&gt;Step 2&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-saml/spinnaker_okta_integration_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;step-3&quot;&gt;Step 3&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-saml/spinnaker_okta_integration_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;step-4&quot;&gt;Step 4&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/spinnaker-saml/spinnaker_okta_integration_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;setting-up-spinnaker&quot;&gt;Setting up Spinnaker&lt;/h1&gt;

&lt;p&gt;We use the &lt;code&gt;InstallSpinnaker.sh&lt;/code&gt; script provided by the Spinnaker team here &lt;a href=&quot;https://github.com/spinnaker/spinnaker/blob/master/InstallSpinnaker.sh&quot;&gt;https://github.com/spinnaker/spinnaker/blob/master/InstallSpinnaker.sh&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Spinnaker itself is broken into several microservices. Looking at &lt;code&gt;/opt&lt;/code&gt; you should see all the different service folders here.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ls /opt
clouddriver  echo  front50  gate  igor  orca  rosco  rush  spinnaker  stackdriver  userdata
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looking at the &lt;code&gt;/opt/spinnaker/config&lt;/code&gt; directory we‚Äôll find all the configurations from the different services. We can override any configuration value with an &lt;code&gt;appname-local.yml&lt;/code&gt; file. The ones we are going to change are &lt;code&gt;gate-local.yml&lt;/code&gt; and &lt;code&gt;settings.js&lt;/code&gt;. When making changes to these files you‚Äôll have to restart their respective service and/or regenerate their configuration file. &lt;code&gt;service gate restart&lt;/code&gt; and &lt;code&gt;/opt/spinnaker/bin/reconfigure_spinnaker.sh&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;gate-configuration&quot;&gt;Gate configuration&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;gate-local.yml

saml:
  enabled: true
  requireAuthentication: true
  url: {okta_idp_url_for_application}
  certificate: {base64_encoded_certificate}
  issuerId: http://www.okta.com/{anyid}
  keyStore: spinnaker.jks
  keyStoreType: JKS
  keyStorePassword: {somepassword}
  keyStoreAliasName: okta
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above properties &lt;code&gt;url&lt;/code&gt; and &lt;code&gt;certificate&lt;/code&gt; will come from Okta after setting up the application. The certificate will have to base64 encoded first before placing it in the config directory.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;issuerId&lt;/code&gt; is a shared uri between both Okta and Spinnaker. You can pick anything for this as long as they share the same id&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;keyStore&lt;/code&gt; is generated using the java keytool utility. Specifically this command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;keytool -importcert -file okta.cert -keystore spinnaker.jks -alias &quot;okta&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;okta.cert&lt;/code&gt; is the previously described certificate not base64 encoded. It produces a file called &lt;code&gt;spinnaker.jks&lt;/code&gt; and shares the alias with &lt;code&gt;keyStoreAliasName&lt;/code&gt; in the &lt;code&gt;gate-local.yml&lt;/code&gt; config. The keytool will prompt for a password which will be shared in the &lt;code&gt;gate-local.yml&lt;/code&gt; config. The &lt;code&gt;spinnaker.jks&lt;/code&gt; file should be placed with your local config or otherwise specified with a correct path in the config to it‚Äôs location.&lt;/p&gt;

&lt;p&gt;Now restart gate &lt;code&gt;service gate restart&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;webapp-configuration&quot;&gt;Webapp configuration&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;settings.js

window.spinnakerSettings = {
  gateUrl: `${gateUrl}`,
  bakeryDetailUrl: `${bakeryBaseUrl}/api/v1/global/logs/?html=true`,
  pollSchedule: 30000,
  defaultTimeZone: &apos;America/Denver&apos;, // see http://momentjs.com/timezone/docs/#/data-utilities/
  providers: {
    gce: {
      defaults: {
        account: `${googlePrimaryAccount}`,
        region: `${googleDefaultRegion}`,
        zone: `${googleDefaultZone}`,
      },
      primaryAccounts: [`${googlePrimaryAccount}`],
      challengeDestructiveActions: [`${googlePrimaryAccount}`],
    },
    aws: {
      defaults: {
        account: `${awsPrimaryAccount}`,
        region: `${awsDefaultRegion}`
      },
      primaryAccounts: [`${awsPrimaryAccount}`],
      primaryRegions: [&apos;eu-west-1&apos;, &apos;us-east-1&apos;, &apos;us-west-1&apos;, &apos;us-west-2&apos;],
      challengeDestructiveActions: [`${awsPrimaryAccount}`],
      preferredZonesByAccount: {}
    }
  },
  whatsNew: {
    gistId: &apos;32526cd608db3d811b38&apos;,
    fileName: &apos;news.md&apos;,
  },
  authEndpoint: &apos;https://YOUR_GATE_HOST/auth/info&apos;,
  authEnabled: true,
  feature: {
    pipelines: true,
    notifications: true,
    fastProperty: true,
    vpcMigrator: false,
    rebakeControlEnabled: true,
    netflixMode: false,
  },
};

window.spinnakerSettings.providers.aws.preferredZonesByAccount[`${awsPrimaryAccount}`] = {
  &apos;us-east-1&apos;: [&apos;us-east-1a&apos;, &apos;us-east-1b&apos;, &apos;us-east-1d&apos;, &apos;us-east-1e&apos;],
  &apos;us-west-1&apos;: [&apos;us-west-1a&apos;, &apos;us-west-1b&apos;, &apos;us-west-1c&apos;],
  &apos;us-west-2&apos;: [&apos;us-west-2a&apos;, &apos;us-west-2b&apos;, &apos;us-west-2c&apos;],
  &apos;eu-west-1&apos;: [&apos;eu-west-1a&apos;, &apos;eu-west-1b&apos;, &apos;eu-west-1c&apos;],
  &apos;ap-northeast-1&apos;: [&apos;ap-northeast-1a&apos;, &apos;ap-northeast-1b&apos;, &apos;ap-northeast-1c&apos;],
  &apos;ap-southeast-1&apos;: [&apos;ap-southeast-1a&apos;, &apos;ap-southeast-1b&apos;],
  &apos;ap-southeast-2&apos;: [&apos;ap-southeast-2a&apos;, &apos;ap-southeast-2b&apos;],
  &apos;sa-east-1&apos;: [&apos;sa-east-1a&apos;, &apos;sa-east-1b&apos;]
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is actually the normal settings.js but we had to add a few extra configuration options which were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;authEndpoint&lt;/code&gt; this should be &lt;code&gt;https://YOUR_GATE_HOST/auth/info&lt;/code&gt;. Normally this is running on localhost:8084&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;authEnabled&lt;/code&gt; should be set to &lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now run &lt;code&gt;/opt/spinnaker/bin/reconfigure_spinnaker.sh&lt;/code&gt; for the settings to regenerate.&lt;/p&gt;

&lt;h1 id=&quot;how-this-works&quot;&gt;How this works&lt;/h1&gt;

&lt;p&gt;When hitting your spinnaker instance with authEnabled it will redirect to the earlier saml url configuration setting we provided to gate. Gate will create a signed message asking for access from Okta. Okta will ask them to sign into their account and redirect them back to spinnaker. Spinnaker validates the returned message signature using the certificate gate has access to.&lt;/p&gt;

&lt;p&gt;One can access http://GATE_URL/auth/info to see your information after successfully authenticating. If you get a 403 forbidden it means you have not authenticated correctly.&lt;/p&gt;

&lt;p&gt;Specific roles and access to accounts can be configured, but we currently have not set this up. Hopefully this is useful enough to at least get you started along the right path.&lt;/p&gt;

&lt;p&gt;Thanks to my team mates, &lt;a href=&quot;https://twitter.com/charliesullivan&quot;&gt;@charliesullivan&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/alexbmeng&quot;&gt;@alexbmeng&lt;/a&gt;, who did some code diving and contributed to setting this up for our environment&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Team workflow using littlechef to manage infrastructure</title>
   <link href="http://0.0.0.0:4000/devops/workingwithteams/continuousdelivery/infrastructure/2014/11/21/team-workflow-using-littlechef-to-manage-infrastructure.html"/>
   <updated>2014-11-21T00:00:00-06:00</updated>
   <id>http://0.0.0.0:4000/devops/workingwithteams/continuousdelivery/infrastructure/2014/11/21/team-workflow-using-littlechef-to-manage-infrastructure</id>
   <content type="html">
&lt;p&gt;&lt;a href=&quot;https://github.com/tobami/littlechef&quot;&gt;Littlechef&lt;/a&gt; is a library allowing one to use chef without a centralized server orchestrating configuration management. It simplifies the testing and deployment model for managing servers by removing a layer from the stack. What this does is let you provision servers using your cli or programmatically in a similar fashion to ansible.&lt;/p&gt;

&lt;p&gt;Recently I was snooping on another team who was doing some work to get chef-solo working in their infrastructure and made a brief comment about littlechef to see if they were moving to it. They made two comments&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/littlechef_workflow/Selection_073.png&quot; alt=&quot;Asking about our workflow with littlechef&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What I took from the above were essentially questions about our workflow with littlechef. How can we test our changes? How do we know our changes will actually work? How do we not mess up real environments? Below is generally how our team makes changes with chef using littlechef. This works for a team of ~25 developers where 3-4 people are focused mostly on chef throughout the day. We manage ~200+ nodes.&lt;/p&gt;

&lt;p&gt;Given that we are attempting to change a recipe that affects all web nodes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Write unit test with chefspec expecting this change.&lt;/li&gt;
  &lt;li&gt;Run &lt;code&gt;fix&lt;/code&gt; against a specific web node in our &lt;em&gt;test&lt;/em&gt; environment. Ensure that the run did not error. This probably looks like &lt;code&gt;fix node:web-n01.test.mydns.com&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;SSH on to that specific web node and make sure our expected change occurred&lt;/li&gt;
  &lt;li&gt;Run a branch build on jenkins which does chefspec, rubocop, and json linting and gives a green checkmark on your github pull request.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If this change includes adding a new community cookbook there is an extra step required which is sync the cookbooks locally before attempting to provision that node with littlechef.&lt;/p&gt;

&lt;p&gt;If this change is required on a group of nodes this is still possible and again would still take place in the &lt;em&gt;test&lt;/em&gt; environment.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;fix --env=test_dfw nodes_with_role:cassandra&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Looking at the above there is actually a region in our environment name. We maintain several different datacenters per environment and we scope all of our &lt;code&gt;fix&lt;/code&gt; commands with the specific region environment. If you want to deploy to all environments you could just run several &lt;code&gt;fix&lt;/code&gt; commands in-tandem or one after the other.&lt;/p&gt;

&lt;p&gt;It is important to use the environment attribute when using &lt;code&gt;nodes_with_role&lt;/code&gt; so if they are not specific enough an accidental provision of other environments does not happen.&lt;/p&gt;

&lt;p&gt;Going back to that pull request where we had a green checkmark. Merging that branch into master doesn‚Äôt do anything immediately (although it could). Currently we have it setup so that after you merge into master you run a job on jenkins that deploys to our lower environments (staging, preprod, and preview). The actual deploys are a series of scripts that build up a runlist per environment. We use a tool called Dreadnot to execute the runlist, but it could just as easily be a series of jenkins jobs. Here is an example of a deploy to our preprod sydney environment which runs in parallel with our staging and preview deploys. Each environment typically has three datacenters ORD, SYD, and DFW.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/littlechef_workflow/chef_run.png&quot; alt=&quot;Chef deploying to our preprod syd environment&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After deploying to all lower environments we typically verify that our expected change happened and begin deploying to production. Production deploys are similar to our lower environments with one key difference. The order of environment deploys first goes to our inactive standby environment, and after completion goes on to our active production environments. We do not have to do a failover to do a successful deploy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/littlechef_workflow/deploy%20order.png&quot; alt=&quot;Order of chef deploys for production&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;provisioning-or-creating-new-nodes&quot;&gt;Provisioning or creating new nodes&lt;/h2&gt;

&lt;p&gt;To provision or create new nodes with littlechef a previous coworker &lt;a href=&quot;http://davehking.com/&quot;&gt;Dave H King&lt;/a&gt; made a library (&lt;a href=&quot;https://github.com/tildedave/littlechef-rackspace&quot;&gt;Littlechef-Rackspace&lt;/a&gt;) to make this really easy on Rackspace. It allows us to run a single command which brings up a node in our environment and runs plugins after it is created. The plugins we currently run install chef via omnibus and creates the node json file with extra information specific to how we setup our environment (private ips, labeling, environment). After the node is active and plugins have been ran it can take a runlist to configure the node as needed and add it to the node.json file.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;fix-rackspace create \
    --username &amp;lt;username&amp;gt; \
    --key &amp;lt;api_key&amp;gt; \
    --region &amp;lt;region&amp;gt; \
    --image &amp;lt;image_id&amp;gt; \
    --flavor &amp;lt;flavor_id&amp;gt; \
    --name &quot;web-n01.preprod.dfw&quot; \
    --public-key &amp;lt;public_key_file&amp;gt; \
    --private-key &amp;lt;private_key_file&amp;gt; \
    --runlist &quot;role[base],role[reach_base],role[reach_dfw_preprod],role[web]&quot; \
    --plugins &quot;omnibus_install_11, bootstrap&quot; \
    --post-plugins &quot;add_role&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of the above can be run in one command, but it can be difficult to remember all of the configuration values needed to add a new node to our environment. The library has an added bonus of being able to use yaml templates which greatly simplify the process of what plugins to use and what runlists we need to add to configure the node. Our plugins are &lt;a href=&quot;https://gist.github.com/riltsken/c9996cf9af2c6b9ecade&quot;&gt;here&lt;/a&gt; and our post plugins after the runlist has been ran are &lt;a href=&quot;https://gist.github.com/riltsken/44103d0e495827758fbe&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-yaml&quot;&gt;image: {imageid-placeholder}
flavor: {flavorid-placeholder}
plugins:
    - omnibus_install_11
    - bootstrap
post-plugins: add_role
use_opscode_chef: false
templates:
  base:
    runlist:
    - &quot;role[base]&quot;
    - &quot;role[reach_base]&quot;
    networks:
    - 00000000-0000-0000-0000-000000000000
    - 11111111-1111-1111-1111-111111111111
  preprod-dfw:
    region: dfw
    environment: reach_dfw_preprod
    runlist:
    - &quot;role[reach_dfw_preprod]&quot;
    networks:
    - 0f4c20c1-4c91-8a69-900d-44ff1fdd6fbd
    secrets-file: secrets-reachpreprod.cfg
  web:
    runlist:
    - &quot;role[reach_web]&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And the new resulting command to spin up a web node in the dfw region for our preprod environment&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;fix-rackspace create --name web-n01.preprod.dfw base preprod-dfw web
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Development Pipeline for the Rackspace Cloud Control Panel</title>
   <link href="http://0.0.0.0:4000/softwaredevelopment/devops/workingwithteams/continuousdelivery/2014/09/21/development-pipeline-for-the-rackspace-cloud-control-panel.html"/>
   <updated>2014-09-21T00:00:00-05:00</updated>
   <id>http://0.0.0.0:4000/softwaredevelopment/devops/workingwithteams/continuousdelivery/2014/09/21/development-pipeline-for-the-rackspace-cloud-control-panel</id>
   <content type="html">
&lt;h2 id=&quot;foreword&quot;&gt;Foreword&lt;/h2&gt;
&lt;p&gt;The Cloud Control Panel at Rackspace has ~30 developers split into 8 subteams. All of them are expected to have the ability to modify any part of the system, however, each subteam has some type of specialized knowledge of the product or infrastructure. Our team has a CI/CD pipeline in which we deploy up to 10 times a day (every hour during business hours). This evolved from a pipeline where every merge triggered a deploy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/Selection_052.png&quot; alt=&quot;Github merge graph&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;development-to-production&quot;&gt;Development to Production?&lt;/h2&gt;
&lt;p&gt;Our pipeline is fairly standard in terms of what we want to happen from development to production. Branch, merge, test, and deploy. We use a private github repository. When a developer takes a story from the backlog they create a feature branch with git. The developer will add the feature and all appropriate unit, integration, and acceptance tests to that branch. During feature development they ask for feedback or a code review and a +1 means they are allowed to merge. This is important as &lt;em&gt;all&lt;/em&gt; branches require a code review before merging. I want to define acceptance level testing as this is a term we use on our team for tests which use selenium to execute real scenarios a user would take in the browser working with the control panel using real upstream APIs.&lt;/p&gt;

&lt;p&gt;Before merging developers run their branch against a builder with their latest hash. Branch builds are a series of jenkins jobs which do things like run all of the unit / integration tests, a subset of the acceptance tests and linting the code. If everything is good the build triggers a script which marks the branch as ‚Äúok to merge‚Äù with a checkmark on github. If it does not pass it gives it an X or ‚Äúbad to merge‚Äù with a link to the failed job.&lt;/p&gt;

&lt;p&gt;Our pipeline has had the same structure for several years, but evolved in how we used it.
Merging code runs the same tasks as the branch builder and more. The additional tasks including compiling, creating a tarball as a distributable, and storing it as an artifact on jenkins. For brevity I will be referring to this as a ‚Äúdist‚Äù. After the dist is created it triggers a deploy job sending this code to a preprod, staging, and preview environment&lt;a href=&quot;The actual deploy process is a bit detailed and left for followup post. Suffice to say it is basically downloading the artifact from jenkins, un-taring the project, symlinking it to a release directory and restarting some services.&quot;&gt;1&lt;/a&gt;. Preprod matches production exactly. Staging uses API‚Äôs that upstream teams have deployed to their preprod environment but not production. Preview is the same as preprod but, with all feature flags flipped on. At this point our acceptance testing suite kicks off and developers validate that they didn‚Äôt break anything in the lower environments. If everything is considered good that dist is deployed to production.&lt;/p&gt;

&lt;h2 id=&quot;the-early-days&quot;&gt;The Early Days&lt;/h2&gt;
&lt;p&gt;In the early days of the Cloud Control Panel our team hovered around ~15 developers. As I mentioned earlier merging triggered deploying to all 3 lower environments and running acceptance level tests against them. This worked okay until we started to grow. As we had more developers join the team we realized that our 30 minute deploy process was taking several hours and even had the possibility of deploying unverified code. How did this happen? As I mentioned previously each merge deployed to the same environment. When we had 5 people merge this would trigger 5 deploys and 5 runs of acceptance level testing. The first round of acceptance tests would be halfway through, but the third merge of code would be on the environment which meant that we don‚Äôt know if the tests completed against a single environment. Developer 1 would deploy to production thinking all the tests were green when, in fact, a defect had slipped through.&lt;/p&gt;

&lt;p&gt;We could have done all these tasks in serial and blocked lower environment deploys on a per merge basis, but this didn‚Äôt fit our ‚Äúdeploy to production fast‚Äù workflow. With five people this would take the fifth person 2.5 hours (30 minutes per merge) to get to production. There are also issues when the 3rd person introduces a defect, but doesn‚Äôt find out until an hour later (not fast feedback) so now the people in line have to wait for a revert or fix. We wanted to get code out there faster. It provides a real benefit for our team and customers to see features, changes, and fixes quickly.&lt;/p&gt;

&lt;p&gt;It was a chaotic environment. Merging became an arduous task. I had no idea how long it would take me to get to production &lt;em&gt;and&lt;/em&gt; I had to guess as to what code was on the lower environments &lt;em&gt;and&lt;/em&gt; constantly watch for other merges coming in. This did not make for a happy developer. What came about from this chaos was an idea called the bus station.&lt;/p&gt;

&lt;h2 id=&quot;the-bus-station&quot;&gt;The Bus Station&lt;/h2&gt;
&lt;p&gt;When a developer merges we take that code all the way to its built dist. Every hour we deploy to the lower environments with the latest &lt;em&gt;good&lt;/em&gt; dist that was built. We called this a bus. At this point the acceptance tests run against the lower environments, which could contain several merges from different developers. The developers on that bus will verify their changes as good or bad and it gets sent off to production. This provides developers with a very structured time period in which their code will be deployed.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/CCPPipeline.png&quot; style=&quot;max-width: 1500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, this system isn‚Äôt perfect either and has some drawbacks. Having a dist that takes too long to build right before the next bus? Wait another hour. Someone introduces a defect which affects the whole bus? Wait another hour.&lt;/p&gt;

&lt;p&gt;This system, however, has created an organized process for our team. I have a better idea for knowing when code will be deployed. Other people on the team can help spot defects as they are working together to deploy rather than individually. The team has built a great deal of tooling around the bus station to interact with our IRC channel and dashboards for dispersing knowledge about the state of a current deploy&lt;/p&gt;

&lt;h2 id=&quot;tooling---irc-commands&quot;&gt;Tooling - IRC Commands&lt;/h2&gt;
&lt;p&gt;We have a custom IRC bot with several useful commands to interact with deploys.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/preprod_commands.png&quot; style=&quot;max-width: 1200px&quot; /&gt;
&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/build_commands.png&quot; alt=&quot;Commands for tracking the current deploy as good or bad&quot; /&gt;
&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/acceptance_ownership_commands.png&quot; style=&quot;max-width: 800px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tooling---dashboards&quot;&gt;Tooling - Dashboards&lt;/h2&gt;

&lt;p&gt;Several dashboards have been created for understanding where the current bus is at in the pipeline and what the current health of our acceptance level tests are.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/bus_dashboard_summary.png&quot; alt=&quot;Dashboard at the top of jenkins&quot; /&gt;
&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/Selection_056.png&quot; alt=&quot;A detailed dashboard for the pipeline&quot; /&gt;
&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/acceptance_test.png&quot; alt=&quot;Acceptance test health for the current bus&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;not-all-pipelines-are-created-equal&quot;&gt;Not All Pipelines Are Created Equal&lt;/h2&gt;
&lt;p&gt;The above tooling has all been built around our large team size. Not all continuous delivery pipelines have to follow what we have done, and I would actually argue most shouldn‚Äôt. We have another service which has only ~6 contributors and 1 or 2 merges a day. That project has a much more manual and rudimentary deploy scheme where team members have to communicate with each other before merging to ensure they don‚Äôt break the pipeline on deploys. This pipeline took less than a week to setup, compared to our main project above where individual team members have built up dashboards and irc commands over several years.&lt;/p&gt;

&lt;h2 id=&quot;the-future&quot;&gt;The Future&lt;/h2&gt;
&lt;p&gt;This isn‚Äôt the end for our deployment pipeline. I would ideally like to see our individual applications for the control panel deployed independently. Currently we tarball our whole repo at once for deploys. Our javascript/css upload to cdn, python/django web backend, twisted and node.js services should all be separate deploy pipelines with their tests ran individually so that they can be deployed faster and with less dependencies. There are still many challenges ahead for us to reach this level, but doing so provides benefits to scaling our team and application.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Why developers need to attend conferences like Gluecon</title>
   <link href="http://0.0.0.0:4000/softwaredevelopment/conference/devops/2014/05/25/why-developers-need-to-attend-conferences-like-gluecon.html"/>
   <updated>2014-05-25T00:00:00-05:00</updated>
   <id>http://0.0.0.0:4000/softwaredevelopment/conference/devops/2014/05/25/why-developers-need-to-attend-conferences-like-gluecon</id>
   <content type="html">
&lt;p&gt;Last week I attended &lt;a href=&quot;http://www.gluecon.com/2014/&quot;&gt;Gluecon&lt;/a&gt;, a developer-centric Cloud+DevOps event in Broomfield, Colorado. Whenever I join one of these conferences (about once or twice a year), I build out goals to maximize my time at the event and the return on investment for my role on the team. In addition, I spoke with many developers from all levels of experience to determine what value these conferences add. The results, while all over the spectrum, speak one clear message: team managers need to send their developers to more conferences. It is one of the best ways to help them grow (and make you as a manager look better). While going to a conference as a speaker holds completely different benefits I will be focusing on what an attendee gets out of it.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.gluecon.com/2014/&quot;&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/gluecon_transparent_logo.png&quot; alt=&quot;Gluecon 2014 logo&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;this-year-i-spent-some-time-asking-other-attendees-what-their-take-away-goals-for-gluecon-were&quot;&gt;This year, I spent some time asking other attendees what their take-away goals for GlueCon were&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;My manager wanted me to research potential new libraries or technologies in the community at large and this conference has some specific ones we are interested in using. I am using the conference as one way to gather information about whether or not we want to use it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This developer was looking to explore ideas and bring insight back home for upcoming project decisions. They don‚Äôt necessarily know what questions to ask, but instead plan to absorb knowledge for any and all possible options. It is also a way for a developer to see what other companies are using that technology to help build confidence in using it.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;As a developer, I wanted to attend this conference as a form of personal education so I know what other tools exist out there and learn about how others use them in their environments.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is a way for them to advance their own knowledge in a domain and add a new tool to their box they might not have heard about. The more options your developer has the more equipped they are to handle problems in their projects.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Networking with other developers who have more experience with the specific technologies I am looking at. Building up this rapport allows me to ask them questions later down the road when I face issues using it and allowing me to easily bypass common pitfalls when I begin to use that technology.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Personally this is one of my favorites. Networking is a huge boon for a developer to grow in their field. Hearing about projects and frameworks is one thing, but building a web of experts that can be referred to later is something else completely.&lt;/p&gt;

&lt;h2 id=&quot;some-key-added-benefits-that-developers-might-not-mention-include&quot;&gt;Some key added benefits that developers might not mention include&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sending developers in a small group&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While it may seem scary pulling several developers out of project development for several days to attend a conference it is hugely beneficial. Sending a group of developers is a team building activity with direct educational benefits. Attending a conference with a coworker helps them form a stronger bond since they are interacting outside of the work place.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Breaking up the monotony of projects on the job&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Sometimes developers can go for weeks or months working on the same project without anything to really shake things up. This means tedious repetition and routine causing boredom or restlessness in a developer. By sending them to a conference it can give them renewed interest in their work.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The first conference I attended was DjangoCon in 2008 held at Google. I was working as an intern for a small non-profit company building a CRM. It was one of the main reasons for the amount of excitement I held for my project.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/djangocon_logo.png&quot; alt=&quot;Djangocon 2008 logo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For the developers, please attend a conference if you have never been. For the managers, I hope you encourage your developers to pick out a meaningful conference to attend this year. A great place to find upcoming conferences is on &lt;a href=&quot;http://lanyrd.com/&quot;&gt;Lanyrd&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>VTHacks and why hackathons are essential for everyone</title>
   <link href="http://0.0.0.0:4000/softwaredevelopment/programming/hackathon/2014/04/22/vthacks-and-why-hackathons-are-essential-for-everyone.html"/>
   <updated>2014-04-22T00:00:00-05:00</updated>
   <id>http://0.0.0.0:4000/softwaredevelopment/programming/hackathon/2014/04/22/vthacks-and-why-hackathons-are-essential-for-everyone</id>
   <content type="html">
&lt;p&gt;Last weekend I had the pleasure of participating in &lt;a href=&quot;http://vthacks.com/&quot;&gt;VTHacks&lt;/a&gt; as a sponsor and judge representing Rackspace. This was not &lt;span class=&quot;underline&quot;&gt;&lt;a href=&quot;https://www.facebook.com/media/set/?set=a.10150347775910404.349700.500210403&amp;amp;type=1&amp;amp;l=5fcdd086bf&quot;&gt;my&lt;/a&gt;&lt;/span&gt; &lt;span class=&quot;underline&quot;&gt;&lt;a href=&quot;http://www.centralfloridafuture.com/mobile/students-startup-winning-business-1.2605980&quot;&gt;first&lt;/a&gt;&lt;/span&gt; &lt;span class=&quot;underline&quot;&gt;&lt;a href=&quot;http://blogs.technet.com/b/bizspark_group_blog/archive/2012/09/19/highlights-from-startupweekend-blacksburg.aspx&quot;&gt;hackathon&lt;/a&gt;&lt;/span&gt;, but it was definitely one of the largest I have attended. The event boasted an RSVP count of ~600 and had sponsors from several big companies which can be found on their event page. The venue was &lt;a href=&quot;http://en.wikipedia.org/wiki/Cassell_Coliseum&quot;&gt;Cassel Coliseum&lt;/a&gt; located at Virginia Tech in Blacksburg, VA.&lt;/p&gt;

&lt;p&gt;Hackathons are now gaining traction as technology becomes more open and available. These events have slowly built up from a group of friends getting together to massive venues bringing people from across the country to work on projects. I was incredibly surprised at the amount of hardware projects specifically at VTHacks. I saw people using VR with the Oculus Rift and combining it with the Kinect to create a virtual environment where two people could interact with each other together. I saw drones covering the entire court, and some taking advantage of google glass to interact with a camera connected to it.&lt;/p&gt;

&lt;p&gt;Here is the important part. Everyone should be involved in these events including non-technical individuals. This is bigger than just a few geeks getting together for a weekend. Students are starting to realize that taking a cookie cutter path of just going to college does not distinguish you enough. You have to tinker and learn and network with other people. Expose yourself to ideas you are not familiar with. When you interact with the community you will get so much out of it. All you have to do is particpate.&lt;/p&gt;

&lt;p&gt;As for how I participated in VTHacks it mostly involved blogging and mentoring. I spent the majority of my time engaging with the teams and ensuring they had everything they needed to succeed in terms of technology questions, free hosting, or what I do on a daily basis as a developer. On Sunday I participated as a judge asking teams what they built and any hurdles they encountered, if at all. In particular we were looking to give out a prize from Rackspace to a team. We actually ended up announcing three winners, &lt;a href=&quot;https://twitter.com/lockboxcloud&quot;&gt;LockBox&lt;/a&gt; (innovative use of file uploads and security), PersonaliAds (tackling an interesting domain), and Space Game in Space (possibly the youngest hackers participating who were in Middle School using threads and networking with Java!)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/rackspace_winners.png&quot; alt=&quot;winners&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I would like to thank &lt;a href=&quot;https://twitter.com/zacklytle&quot;&gt;Zack Lytle&lt;/a&gt; for giving me the opportunity to attend and help as he did most of the work with organizing Rackspace as a sponsor and I just kind of showed up to help :).&lt;/p&gt;

&lt;p&gt;The next Blacksburg hackathon is at &lt;a href=&quot;https://heyo.com/hackathon&quot;&gt;Heyo&lt;/a&gt; (&lt;a href=&quot;https://www.facebook.com/events/234179516771748/?ref=22&quot;&gt;facebook event&lt;/a&gt;) with a prize of $1000. Good luck!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Making runbooks more useful by exposing them through monitoring</title>
   <link href="http://0.0.0.0:4000/devops/infrastructure/monitoring/2014/04/19/making-runbooks-more-useful-by-exposing-them-through-monitoring.html"/>
   <updated>2014-04-19T00:00:00-05:00</updated>
   <id>http://0.0.0.0:4000/devops/infrastructure/monitoring/2014/04/19/making-runbooks-more-useful-by-exposing-them-through-monitoring</id>
   <content type="html">
&lt;p&gt;In the &lt;a href=&quot;/devops/infrastructure/2014/03/16/how-server-message-of-the-day-improved-our-devops-team.html&quot;&gt;Server Message Of The Day (MOTD) post&lt;/a&gt;, I mentioned the importance of sharing &lt;a href=&quot;http://en.wikipedia.org/wiki/Tribal_knowledge&quot;&gt;tribal knowledge&lt;/a&gt; across teams on fixing infrastructure issues. When any of our monitoring alarms kick off, any team member should be equipped to take action on the alarm, but we operate with so many different technologies that no one person could possibly be an expert in all of them. Most operations teams create &lt;a href=&quot;http://en.wikipedia.org/wiki/Runbook&quot;&gt;runbooks&lt;/a&gt; for common tasks, but we took it one step further and created runbooks for every alarm in our system. They don‚Äôt exactly cover every possible reason for an alarm triggering, but will always help to provide context for someone that doesn‚Äôt regularly deal with that subsystem.&lt;/p&gt;

&lt;p&gt;Our runbooks are composed of the node‚Äôs title and definition, its role in the system, and important config files. After that block is a section for all the system‚Äôs monitoring alerts and what actions you can take to investigate or fix them. This is one of the runbooks for Cassandra:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/node_description.png&quot; alt=&quot;A description of the nodes role and configuration files&quot; /&gt;
&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/context_and_actions.png&quot; alt=&quot;The actions we expect someone to take when initially debugging an issue when that alarm triggers&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;triggered-alarms-link-the-runbook&quot;&gt;Triggered alarms link the runbook&lt;/h2&gt;

&lt;p&gt;We use IRC for team communication since we‚Äôre all distributed. The alerts will stream into the channel via bot with direct links to the runbooks and every triggered alarm. While we do have a proper escalation path through &lt;a href=&quot;https://www.pagerduty.com/&quot;&gt;PagerDuty&lt;/a&gt;, this keeps the whole team aware of issues and gives anyone an easy path for investigation and action.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/irc_example.png&quot; alt=&quot;One of the ways people get notified of issues and a link to the runbook for what to do&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Multi-region logging architecture with Logstash, Kibana, and ElasticSearch</title>
   <link href="http://0.0.0.0:4000/devops/infrastructure/logging/2014/03/25/multi-region-logging-architecture-with-logstash-and-kibana.html"/>
   <updated>2014-03-25T05:24:15-05:00</updated>
   <id>http://0.0.0.0:4000/devops/infrastructure/logging/2014/03/25/multi-region-logging-architecture-with-logstash-and-kibana</id>
   <content type="html">
&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;On my team right now we are using rsyslog with &lt;a href=&quot;http://graylog2.org/&quot;&gt;Graylog2&lt;/a&gt; and &lt;a href=&quot;http://www.elasticsearch.org/&quot;&gt;ElasticSearch&lt;/a&gt; to handle our logging infrastucture. The current setup is not ideal as we are distributed multi-region for our application in 3 datacenters (ORD, DFW, SYD) and each one has it‚Äôs own cluster setup to use Graylog2 and ElasticSearch. This means if someone wanted to search through logs you would have to pick that specific region‚Äôs Graylog2 instance. The original reason for this setup was that we had our logging infrastructure setup before multi-region was in place and we had to make a decision about how much time we wanted to spend setting it up. We chose for the quickest option as we had other product work that needed to get done before improving our logging infrastructure. This has proved to be a costly choice for us. Our current system has degraded to the point where we barely use our Graylog2 interface anymore. There are several reasons for this. One is that it is frustrating to switch between the multiple region interfaces and setup the same filters for each one. Another is that the version of Graylog2 + ElasticSearch we are working with are struggling to keep up with the amount of logs we have. It has gotten to the point where even simple queries executed on Graylog2 cause alerts to fire on our ElasticSearch cluster requiring action from us to help restore it.&lt;/p&gt;

&lt;p&gt;Our backlog has some stories in place to remedy this situation, but are not on our radar for another few months. We recently had a hackweek and decided to experiment with some ideas and technology on what we want to use. Most of these ideas come from another team at Rackspace working on &lt;a href=&quot;http://www.rackspace.com/cloud/auto-scale/&quot;&gt;Autoscale&lt;/a&gt;. Our idea is slightly modified, but the same general concept. None of this is currently implemented in a production like environment and most of it was setup in a test environment to play around with during our hackweek. The technologies in play here are &lt;a href=&quot;http://logstash.net/&quot;&gt;Logstash&lt;/a&gt;, &lt;a href=&quot;http://www.elasticsearch.org/overview/kibana/&quot;&gt;Kibana&lt;/a&gt;, and ElasticSearch.&lt;/p&gt;

&lt;p&gt;I have to explain our current architecture a little bit first to setup why we would use the solution proposed first. The Cloud Control Panel at Rackspace is hosted in three different datacenters, ORD (US and Europe), DFW (backup), and SYD (Oceanic). All of our US and European traffic goes to ORD, while our Oceanic traffic goes to SYD. DFW is left as a warm backup that is ready in case any issue happens in the other two DC‚Äôs. What we didn‚Äôt want to do was make the same mistake as before with our logging and have multiple regional interfaces to access our logs. This meant collecting all of our logs and putting it into one datacenter for searching and querying. What that required was having each datacenter ship their logs to the collector which then puts these logs into ElasticSearch. There exists a node in each datacenter, called the broker, which then ships to the collector the logs for that datacenter. So let‚Äôs go over this one more time. There is one collector node, one broker node per region shipping to the collector, and all nodes in the same datacenter ship nodes to their specified broker. We can then browse logs through our collector which will be running Kibana.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/multi-region logging architecture.png&quot; alt=&quot;Full picture of proposed multi-region logging infrastructure&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;hackweek&quot;&gt;Hackweek&lt;/h2&gt;

&lt;p&gt;For the hackweek we broke up different portions of the infrastructure to different team members. I tackled setting up the broker node for a region and the collector. Having all nodes in the specified datacenter ship logs to the broker over a private network, which then in turn sent its logs to the collector on a public network over an encrypted channel. Our team already uses logstash for all of our nodes to send metrics to statsd, so most of the initial boostrapping of getting the logstash agent installed and running was already handled. We use Chef and Berkshelf to manage our infrastructure, which means we are using the &lt;a href=&quot;https://github.com/lusis/chef-logstash&quot;&gt;logstash cookbook&lt;/a&gt; at version 0.7.6 at the time of this writing. Earlier versions of the cookbook had all the configuration rules for logstash written as node attributes which we put at the role level. As this method of creating rules was deprecated I moved them into configuration files that sit in the logstash conf.d directory. Logstash reads these config files in order, I found &lt;a href=&quot;https://groups.google.com/forum/#!topic/logstash-users/eNYmpFueHtM&quot;&gt;a convention I liked here&lt;/a&gt; about numbering each config file which I decided to follow.&lt;/p&gt;

&lt;p&gt;To get all nodes in a specific datacenter to send their logs to the broker I decided to use tags to handle forwarding the logs I wanted. An example of what this would look like via config files would be the following&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-erb&quot;&gt;00_input_base.conf

input {
  file {
    &apos;path&apos; =&amp;gt; &apos;/var/log/rackspace-monitoring-agent.log&apos;,
    &apos;type&apos; =&amp;gt; &apos;rackspace-monitoring-agent&apos;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;language-erb&quot;&gt;01_input_apache.conf

input {
  file {
    &apos;path&apos; =&amp;gt; &apos;/var/log/apache2/error.log&apos;
    &apos;type&apos; =&amp;gt; &apos;apache-error&apos;
    &apos;tags&apos; =&amp;gt; [&apos;broker&apos;]
  }
  file {
    &apos;path&apos; =&amp;gt; &apos;/var/log/apache2/access.log&apos;
    &apos;type&apos; =&amp;gt; &apos;apache-access&apos;
    &apos;tags&apos; =&amp;gt; [&apos;broker&apos;]
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;language-erb&quot;&gt;90_forward_to_broker.conf

output {
  if &apos;broker&apos; in [tags] {
    redis {
      &apos;host&apos; =&amp;gt; &apos;192.168.9.1&apos;
      &apos;data_type&apos; =&amp;gt; &apos;list&apos;
      &apos;key&apos; =&amp;gt; &apos;logstash&apos;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/multi-region logging - web to broker.png&quot; alt=&quot;Specific datacenter logging from application nodes to broker&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Basically what logstash would do is take all new events from the apache error and access logs, tag them with ‚Äòbroker‚Äô, and when logstash checks its outputs any events tagged with ‚Äòbroker‚Äô would get sent to our broker node. This is useful for us since we use logstash for processing and forwarding metrics to statsd from our logs as well. At this point we now have nodes in our environment forwarding to their local broker node in their datacenter.&lt;/p&gt;

&lt;p&gt;The next step is to forward our logs to the collector. To do this we create a different set of conf.d files for our logstash agent to run on the broker node. For this portion we were originally going to use stunnel to create an encrypted channel for the logs to be sent over to the collector, however, as I was reading about the different inputs and outputs supported by logstash I stumbled on &lt;a href=&quot;https://github.com/elasticsearch/logstash-forwarder&quot;&gt;lumberjack&lt;/a&gt;. Now, I actually had quite a few issues with understanding how lumberjack should be used in the context of logstash. What I see now is that it can either &lt;strong&gt;REPLACE&lt;/strong&gt; the logstash agent as a log handler and forwarder or logstash can &lt;strong&gt;CREATE&lt;/strong&gt; a lumberjack instance on the fly to send events as output or read events forwarded by lumberjack. In the first case, you would actually have to compile and build the lumberjack project and run the agent as a service. In the second case the logstash agent handles all of that and one should just use the inputs and outputs as normal.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-erb&quot;&gt;91_forward_to_collector.conf

input {
  redis {
    &apos;host&apos; =&amp;gt; &apos;&amp;lt;%= node[&quot;logstash&quot;][&quot;broker_ip&quot;] %&amp;gt;&apos;
    &apos;data_type&apos; =&amp;gt; &apos;list&apos;
    &apos;key&apos; =&amp;gt; &apos;logstash&apos;
  }
}

output {
  lumberjack {
    &apos;hosts&apos; =&amp;gt; [&apos;&amp;lt;%= node[&quot;logstash&quot;][&quot;collector_ip&quot;] %&amp;gt;&apos;]
    &apos;port&apos; =&amp;gt; &amp;lt;%= node[&quot;logstash&quot;][&quot;forwarder&quot;][&quot;port&quot;] %&amp;gt;
    &apos;ssl_certificate&apos; =&amp;gt; &apos;&amp;lt;%= node[&quot;selfsigned_ssl&quot;][&quot;directory&quot;] %&amp;gt;&amp;lt;%= node[&quot;selfsigned_ssl&quot;][&quot;ssl_cert&quot;] %&amp;gt;&apos;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;language-erb&quot;&gt;92_lumberjack_collector.conf

input {
  lumberjack {
    &apos;host&apos; =&amp;gt; &apos;127.0.0.1&apos;
    &apos;port&apos; =&amp;gt; &amp;lt;%= node[&quot;logstash&quot;][&quot;forwarder&quot;][&quot;port&quot;] %&amp;gt;
    &apos;ssl_certificate&apos; =&amp;gt; &apos;&amp;lt;%= node[&quot;selfsigned_ssl&quot;][&quot;directory&quot;] %&amp;gt;&amp;lt;%= node[&quot;selfsigned_ssl&quot;][&quot;ssl_cert&quot;] %&amp;gt;&apos;
    &apos;ssl_key&apos; =&amp;gt; &apos;&amp;lt;%= node[&quot;selfsigned_ssl&quot;][&quot;directory&quot;] %&amp;gt;&amp;lt;%= node[&quot;selfsigned_ssl&quot;][&quot;ssl_key&quot;] %&amp;gt;&apos;
  }
}

output {
  redis {
    &apos;host&apos; =&amp;gt; &apos;127.0.0.1&apos;
    &apos;data_type&apos; =&amp;gt; &apos;list&apos;
    &apos;key&apos; =&amp;gt; &apos;logstash&apos;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unfortunately I ran out of time during our hackweek due to other issues I had to look at outside of this project to get the implementation down 100% but this is the rough idea for how it would look. I hope to make a follow up post when we have fully implemented the desired architecture. For now, this documents some of the learnings I gained while working on this project for a few days.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>How a server MOTD improved our DevOps team</title>
   <link href="http://0.0.0.0:4000/devops/infrastructure/2014/03/16/how-server-message-of-the-day-improved-our-devops-team.html"/>
   <updated>2014-03-16T10:54:14-05:00</updated>
   <id>http://0.0.0.0:4000/devops/infrastructure/2014/03/16/how-server-message-of-the-day-improved-our-devops-team</id>
   <content type="html">
&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;
&lt;p&gt;Our Infrastructure team for the Cloud Control Panel at Rackspace has around ~200 public cloud servers across production, preproduction, staging, and test environments. At a high level our general layout for hosting the Cloud Control Panel includes nodes of several different types. We have load balancers running apache. Web nodes which serve the base content with Django. Javascript served from a cdn (content delivery network). Twisted servers which proxy requests for making calls to Rackspace apis from the frontend. A cluster of Cassandra nodes for managing sessions, preferences, and api cache data. All of these nodes are managed and provisioned using &lt;a href=&quot;https://github.com/tobami/littlechef&quot;&gt;littlechef&lt;/a&gt; (chef-solo) combined with &lt;a href=&quot;https://github.com/tildedave/littlechef-rackspace&quot;&gt;littlechef-rackspace&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When I first started working on this team we had almost no documentation about how the different types of servers in our environment were setup. When you would SSH onto a node to debug an issue or alert it would take a little extra digging to get started. While we do use chef for configuration of our servers it would take awhile to trace all of the different recipes, where they install services, what scripts you can run, and other useful information about that node. Another issue is making sure that developers at all levels have access to the same information. We want to make sure all, from junior to senior, developers are able to tackle issues that arise.&lt;/p&gt;

&lt;p&gt;To that end &lt;a href=&quot;https://github.com/AMeng&quot;&gt;Alex Meng&lt;/a&gt; one of the developers on the team took it upon himself during a hackday to improve the process. He did this by generating MOTD‚Äôs for our servers via chef. Below is a Cassandra node in our test environment. The MOTD is great for immediately being able to start diagnosing issues without having to look at chef for where everything on this node is located.
&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/reach_cass_motd.png&quot; alt=&quot;Example of a Cassandra node MOTD in our test environment. Full picture.&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;load-and-network-information&quot;&gt;Load and network information&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/reach_cass_motd_1.png&quot; alt=&quot;Top of MOTD describing load and network interfaces. Cropped.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When you first ssh into a node the very top shows some basic &lt;strong&gt;load information&lt;/strong&gt; about the node and what &lt;strong&gt;network interfaces&lt;/strong&gt; it has available. The network interfaces has proven useful if you have services running on different interfaces and need quick access to that information. For example, on this cassandra node we would access the cassandra cli (cqlsh) from the private network interface.&lt;/p&gt;

&lt;h2 id=&quot;node-description&quot;&gt;Node description&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/reach_cass_motd_2.png&quot; alt=&quot;Middle of MOTD describing project name, node name, environment, hostname, and region. Cropped.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next piece of information we add is our &lt;strong&gt;project name&lt;/strong&gt; along with the &lt;strong&gt;node name&lt;/strong&gt; (cassandra, load balancer, proxy, web), &lt;strong&gt;region&lt;/strong&gt; (dfw, ord, syd), &lt;strong&gt;environment&lt;/strong&gt; (test, staging, preprod, production) and &lt;strong&gt;hostname&lt;/strong&gt; which is blurred out. This helps a person ensure they know they are on the right node. The environment text is large so people are more careful if they are jumping on several boxes, some of which could be production.&lt;/p&gt;

&lt;h2 id=&quot;services-and-location-of-important-information&quot;&gt;Services and location of important information&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://d1dj72mlaoziwu.cloudfront.net/reach_cass_motd_3.png&quot; alt=&quot;Middle of MOTD describing project name, node name, environment, hostname, and region. Cropped.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next section describes the &lt;strong&gt;services running&lt;/strong&gt; on the box. This one only happens to be running Cassandra, but some nodes might be running multiple services (in general, our nodes are assigned a single function, but some applications require multiple services on a box). It will also describe where &lt;strong&gt;logs&lt;/strong&gt; and &lt;strong&gt;important configuration&lt;/strong&gt; files are located on the node. Other things we include sometimes on here are location of &lt;strong&gt;script files&lt;/strong&gt; or &lt;strong&gt;cron jobs&lt;/strong&gt; that are running on the system. At the end of our MOTD is a link to the &lt;strong&gt;documentation&lt;/strong&gt; which describes in detail the role of this node in our architecture.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Our implementation of MOTD‚Äôs is done via a chef recipe. All of our nodes have a ‚Äúshort_name‚Äù attribute which we use to identify which MOTD to use. We store these MOTD‚Äôs as cookbook files and every node has a MOTD recipe which dumps the correct MOTD onto that node.&lt;/p&gt;

&lt;p&gt;In the past year that we have had MOTD‚Äôs on all of our nodes I realize how important and helpful it is to disperse information about our architecture and make it easier to enable other developers to operate on it. The MOTD provides one key piece for organizing this information immediately when acting on a single node.&lt;/p&gt;

</content>
 </entry>
 

</feed>
